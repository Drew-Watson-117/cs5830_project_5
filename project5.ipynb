{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier for Determining Whether a Song is Explicit\n",
    "\n",
    "Our goal is to create a Naive Bayes Classifier model for determining whether a song is explicit given its lyrics. Our data was obtained using the Musixmatch API. \n",
    "\n",
    "We got the top chart songs from several English speaking countries. Then, we got the lyrics for each of those songs and whether the song is explicit. We then wrote that data to a .csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read in the data. Then, we stem it and remove stop words to make things more simple for our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv(\"data/tracks.csv\",index_col=0)\n",
    "tracks.dropna(inplace=True)\n",
    "tracks.reset_index(inplace=True)\n",
    "del tracks[\"index\"]\n",
    "\n",
    "# Stemming words and removing stop words\n",
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmedLyricsList = []\n",
    "for lyrics in tracks['lyrics']:\n",
    "    lyricsList = lyrics.split(\" \")\n",
    "    stemmedLyrics = [stemmer.stem(word) for word in lyricsList if word.lower() not in stopwords.words('english')]\n",
    "    stemmedLyrics = ' '.join(stemmedLyrics)\n",
    "    stemmedLyricsList.append(stemmedLyrics)\n",
    "tracks = tracks.assign(stemmed_lyrics=stemmedLyricsList)\n",
    "tracks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our input features and output classes. This will be our stemmed lyrics and the explicit flag for each song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input Features and Output Classes\n",
    "X = tracks['stemmed_lyrics']\n",
    "y = tracks['explicit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we make a function for our Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier Function\n",
    "\n",
    "def naive_bayes(X,y, showConfusionMatrix=False):\n",
    "    # Getting training and testing X and y\n",
    "    # Convert text to numerical features\n",
    "    vectorizer = CountVectorizer()\n",
    "    Xvec = vectorizer.fit_transform(X)\n",
    "\n",
    "    # Split into training and testing\n",
    "    trainX, testX, trainY, testY = train_test_split(Xvec,y)\n",
    "\n",
    "    # Train the classifier\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(trainX,trainY)\n",
    "\n",
    "    # Predict the test data\n",
    "    predictY = classifier.predict(testX)\n",
    "\n",
    "    # Get metrics for classifier (precision, recall, fscore, support)\n",
    "    metrics = {}\n",
    "    p,r,f,s = precision_recall_fscore_support(testY,predictY)\n",
    "\n",
    "    metrics[\"precision\"] = p\n",
    "    metrics[\"recall\"] = r\n",
    "    metrics[\"f-score\"] = f\n",
    "    metrics[\"support\"] = s\n",
    "\n",
    "    for metric in metrics.keys():\n",
    "        print(f\"{metric}: {metrics[metric]}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    if showConfusionMatrix:\n",
    "        labels = [\"Not Explicit\", \"Explicit\"]\n",
    "        confusionMatrix = confusion_matrix(predictY,testY)\n",
    "        display = ConfusionMatrixDisplay(confusion_matrix=confusionMatrix, display_labels=labels)\n",
    "        display.plot()\n",
    "\n",
    "    return classifier, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function to obtain the classifier and the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run naive bayes function\n",
    "classifier, metrics = naive_bayes(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 10-fold cross validation to evaluate our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kValue = 10\n",
    "kfold = KFold(kValue,shuffle=True)\n",
    "metrics_averages = {\"precision\": 0, \"recall\": 0, \"f-score\": 0, \"support\": 0}\n",
    "for train, test in kfold.split(X,y):\n",
    "    classifier, metrics = naive_bayes(X,y)\n",
    "    for metric in metrics.keys():\n",
    "        metrics_averages[metric] += metrics[metric]\n",
    "for metric in metrics_averages.keys():\n",
    "    metrics_averages[metric] = metrics_averages[metric]/kValue\n",
    "\n",
    "for metric in metrics.keys():\n",
    "    print(f\"average {metric}: {metrics_averages[metric]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
